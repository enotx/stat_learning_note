# 第11章 条件随机场
conditional random field，CRF
是给定一组输入随机变量条件下，另一组输出随机变量的条件概率分布模型
其特点是随机变量构成马尔可夫随机场

## 11.1概率无向图模型
probabilistic undirected model，又称马尔可夫随机场（Markov random field），是一个由无向图表示的联合概率分布

### 11.1.1 模型定义
图（graph）是由结点（node）及连接结点的边（edge）组成的集合
结点和边分别记作v和e，结点和边的集合分别记作V和E，图记作$G=(V,E)$
无向图是指边没有方向的图

概率图模型（probabilistic graphical model）是由图表示的概率分布。设有联合概率分布$P(Y)，Y \in \mathcal{Y}$是一组随机变量。由无向图$G=(V,E)$表示概率分布$P(Y)$，即在图G中，结点$v \in V$表示一个随机变量$Y_v$，$Y=(Y_v)_{v \in V}$；边$e \in E$表示随机变量之间的概率依赖关系

给定一个联合概率分布$P(Y)$和表示它的无向图$G$。首先定义无向图表示随机变量之间存在的成对马尔可夫性（pairwise Markov property）、局部马尔可夫性（local Markov property）和全局马尔可夫性（global Markov property）

- 成对马尔可夫性：
设u和v是无向图G中任意两个没有边连接的结点，结点u和v分别对应随机变量$Y_u$和$Y_v$。其他所有结点为O，对应的随机变量组是$Y_O$。
成对马尔可夫性是指给定随机变量组$Y_O$的条件下，随机变量$Y_u$和$Y_v$是条件独立的，即：
$$
P(Y_u, Y_v| Y_O) = P(Y_u | Y_O) P(Y_v | Y_O)
\tag{11.1}
$$
- 局部马尔可夫性：设$v \in V$是无向图G中任意一个结点，W是与v有边连接的所有结点，O是v、W以外对的所有结点。v表示的随机变量是$Y_v$，W表示的随机变量组是$Y_w$，O表示的随机变量组是$Y_O$
局部马尔可夫性是指在给定的随机变量组$Y_W$的条件下，随机变量$Y_v$与随机变量组$Y_O$是独立的，即：
$$
P(Y_v,Y_O|Y_W) = P(Y_v|Y_W)P(Y_O|Y_W)
\tag{11.2}
$$
在$P(Y_O|Y_W) > 0$时，等价的：
$$
P(Y_v|Y_W) = P(Y_v|Y_w,Y_O)
\tag{11.3}
$$
- 全局马尔可夫性：
设结点集合A,B是在无向图G中被结点集合C分开的任意结点集合（见图）
![](leanote://file/getImage?fileId=5c8f758dee2b2b0e38000003)
结点集合A,B和C所对应的随机变量组分别是$Y_A，Y_B，Y_C$。
全局马尔可夫性是指给定随机变量组$Y_C$的条件下，随机变量组$Y_A$和$Y_B$是条件独立的，即：
$$
P(Y_A,Y_B|Y_C) = P(Y_A|Y_C)P(Y_B|Y_C)
\tag{11.4}
$$

上述成对、局部、全局的马尔可夫性定义是等价的

下定义概率无向图模型：
#### 定义11.1（概率无向图模型）
设有联合概率分布$P(Y)$，由无向图$G=(V,E)$表示，在图G中，结点表示随机变量，边表示随机变量之间的依赖关系。
如果联合概率分布$P(Y)$满足成对、局部或全局马尔可夫性，就称此联合爱侣分布为概率无向图模型，或马尔可夫随机场

### 11.1.2 概率无向图模型的因子分解
#### 定义11.2（团与最大团）
无向图G中任何两个结点均有边连接的结点子集称为团（clique）。
若C是无向图G的一个团，并且不能再加进任何一个G的结点使其称为一个更大的团，则称C为最大团（maximal clique）

将概率无向图模型的联合概率分布，表示为其最大团上的随机变量的函数乘积形式的操作，称为概率无向图模型的因子分解（factorization）

给定概率无向图模型，设其无向图为G，C为G上的最大团，$Y_C$表示C对应的随机变量。
那么概率无向图模型的联合概率分布$P(Y)$可以写作所有最大团C上的函数$\Psi_C(Y_C)$的乘积形式，即：
$$
P(Y) = \frac{1}{Z} \prod_C \Psi_C(Y_C)
\tag{11.5}
$$
其中，Z是规范化因子（normalization factor）：
$$
Z = \sum_Y \prod_C \Psi_C (Y_C)
\tag{11.6}
$$
规范化因子保证P(Y)构成一个概率分布
函数$\Psi_C (Y_C)$称为势函数（potential function）。这里要求势函数$\Psi_C (Y_C)$是严格正的。通常定义为指数函数：
$$
\Psi_C (Y_C) = \exp \{ - E(Y_C) \}
\tag{11.7}
$$

#### 定理11.1（Hammerskey-Clifford定理）
概率无向图模型的联合概率$P(Y)$可以表示为如下形式：
$$\begin{align}
P(Y) = \frac{1}{Z} \prod_C \Psi_C(Y_C) \\
Z = \sum_Y \prod_C \Psi_C (Y_C)
\end{align}$$
其中，C是无向图的最大团，$Y_C$是结点对应的随机变量，$\Psi_C(Y_C)$是C上定义的严格正函数，乘积是在无向图所有的最大团上进行的

## 11.2 条件随机场的定义与形式
### 11.2.1 条件随机场的定义

条件随机场（conditional random field）是给定随机变量X条件下，随机变量Y的马尔可夫随机场
这里主要介绍**线性链条件随机场**（linear chain conditional random field），可以用于解决标注等问题
这时，在条件概率模型$P(Y|X)$中，Y是输出变量，表示标记序列；X是输入变量，表示需要标注的观测序列。也把标记序列称为状态序列（对应HMM中的概念）
学习时，利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型$\hat{P}(Y|X)$；预测时，对于给定的输入序列x，求出条件概率$\hat{P}(y|x)$最大的输出序列$\hat{y}$

#### 定义11.3（条件随机场）
设X与Y是随机变量
P(Y|X)是给定X的条件下，Y的条件概率分布
若随机变量Y构成了一个由无向图G=(V,E)表示的马尔可夫随机场，即：
$$
P(Y_v|X,Y_w,w \ne v) = P(Y_v | X,Y_w,w \sim v)
\tag{11.8}
$$
对任意结点v成立，则称条件概率分布$P(Y|X)$为条件随机场
式中，$w \sim v$表示在图$G=(V,E)$中与结点v有边连接的所有结点$w$
$w \ne v$表示结点v以外的所有结点
$Y_v, Y_u$与$Y_w$为结点$v,u$与$w$对应的随机变量

在定义中并没有要求X和Y具有相同的结构。现实中，一般假设X和Y有有相同的图结构
这里主要考虑无向图为如图所示的线性链的情况，即：
$$
G = \left(V = \{1,2,\cdots,n \}),E=\{(i,i+1)\} \right),\,i=1,2,\cdots,n-1
$$
![](leanote://file/getImage?fileId=5c8f8522ee2b2b0e38000004)
在此情况下，$X=(X_1,X_2,\cdots,X_n)$，$Y=(Y_1,Y_2,\cdots,Y_n)$，最大团是相邻两个结点的集合。线性链条件随机场有下面的定义

#### 定义11.4（线性链条件随机场）
设$X=(X_1,X_2,\cdots,X_n)$，$Y=(Y_1,Y_2,\cdots,Y_n)$均为线性链表示的随机变量序列，若在给定随机变量序列X的条件下，随机变量序列Y的条件概率分布$P(Y|X)$构成条件随机场，即满足马尔可夫性
$$\begin{align}
P(Y_i | X,Y_1,\cdots,Y_{i-1},Y_{i+1},\cdots,Y_n) = P(Y_i|X,Y_{i-1},Y_{i+1})\\
i = 1,2,\cdots,n（在i=1和n时只考虑单边）
\tag{11.9}
\end{align}$$
则称$P(Y|X)$为线性链条件随机场。在标注问题中，X表示输入观测序列，Y表示对应的输入标记序列或状态序列


### 11.2.2 条件随机场的参数化形式
#### 定理11.2（线性链条件随机场的参数化形式）
设$P(Y|X)$为线性链条件随机场，则在随机变量X的取值为x的条件下，随机变量Y的取值为y的条件概率具有如下形式：
$$
P(y|x) = \frac{1}{Z(x)} \exp \left( \sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) + \sum_{i,l} \mu_l s_l(y_i,x,i) \right)
\tag{11.10}
$$
其中
$$
Z(x) = \sum_y \exp \left( \sum_{i,k} \lambda_k t_k (y_{i-1}, y_i, x, i) + \sum_{i,l} \mu_l s_l(y_i,x,i) \right)
\tag{11.11}
$$
式中，$t_k$和$s_l$是特征函数，$\lambda_k$和$\mu_l$是对应的权值。
$Z(x)$是规范化因子，求和是在所有可能的输出序列（标记序列）上进行的

$t_k$是定义在边上的特征函数，称为转移特征，依赖与当前和前一个位置
$s_l$是是定义在结点上的特征函数，称为状态特征，依赖于当前位置
$t_k$和$s_l$都依赖位置，是局部特征函数
通常，特征函数$t_k$和$s_l$的取值为1或0（满足条件时1，否则0）

### 11.2.3 条件随机场的简化形式
注意到：(11.10)中同一特征在各个位置都有定义
可以对同一个特征在各个位置求和，将局部特征函数转化为一个全局特征函数
这样就可以将条件随机场写成权值向量和特征向量的内积形式，即条件随机场的简化形式

为简便起见，首先将转移特征和状态特征及其权值用统一的符号表示
设有$K_1$个转移特征，$K_2$个状态特征，$K=K_1+K_2$，记：
$$
f_k(y_{i-1},y_i,x,i) = 
\begin{cases}
t_k(y_{i-1},y_i,x,i),\,&k=1,2,\cdots,K_1 \\
s_l(y_i,x,i),\, &k = K_1+l; l=1,2,\cdots,K_2
\end{cases}
\tag{11.12}
$$
然后，对转移和状态特征在各个位置i求和，记作：
$$
f_k(y,x) = \sum_{i=1}^n f_k(y_{i-1},y_i,x,i),\, k=1,2,\cdots,K
\tag{11.13}
$$
用$w_k$表示特征$f_k(y,x)$的权值，即：
$$
w_k=
\begin{cases}
\lambda_k, &k=1,2,\cdots,K_1 \\
\mu_l, &k=K_1+l;l=1,2,\cdots,K_2
\end{cases}
\tag{11.14}
$$
于是，条件随机场(11.11)~(11.12)可以表示为
$$\begin{align}
P(y|x) = \frac{1}{Z(x)} \exp \sum_{k=1}^{K} w_k f_k(y,x) \tag{11.15} \\
Z(x) = \sum_y \exp \sum_{k=1}^{K} w_k f_k(y,x) \tag{11.16} 
\end{align}$$
若以$w$表示权值向量，即
$$
w = (w_1,w_2,\cdots,w_K)^T
\tag{11.17}
$$
以$F(y,x)$表示全局特征向量，即：
$$
F(y,x)= (f_1(y,x),f_2(y,x),\cdots,f_K(y,x))^T
\tag{11.18}
$$
则条件随机场可以写成向量$w$与$F(y,x)$的内积形式：
$$
P_w(y|x) = \frac{\exp(w \cdot F(y,x))}{Z_w(x)}
\tag{11.19}
$$
其中，
$$
Z_w(x) = \sum_y \exp(w \cdot F(y,x))
\tag{11.20}
$$


### 11.2.4 条件随机场的矩阵形式
假设$P_w(y|x)$，是由(11.15)~(11.16)给出的线性链条件随机场，表示对给定观测序列x，相应的标记序列y的条件概率
引进特殊的七点和重点状态标记：$y_0=$start，$y_{n+1}$=stop
这时$P(y|x)$可以通过矩阵形式表示

对观测序列x的每一个位置$i=1,2,\cdots,n+1$，定义一个m阶的矩阵（m是标记$y_i$取值的个数）：
$$\begin{align}
M_i(x) = \left[ M_i(y_{i-1},y_i | x) \right] \tag{11.21} \\
M_i(y_{i-1},y_i | x) = \exp \left( W_i(y_{i-1},y_i | x) \right) \tag{11.22} \\
\left( W_i(y_{i-1},y_i | x) \right) = \sum_{k=1}^K w_k f_k (y_{i-1},y_i,x,i) \tag{11.23}
\end{align}$$
这样，给定观测序列x，相应标记序列y的非规范化概率可以通过该序列n+1个矩阵适当元素的乘积$\prod_{i=1}^{n+1} M_i(y_{i-1},y_i | x)$表示
于是，条件概率$P_w(y|x)$是
$$
P_w(y|x) = \frac{1}{Z_w(x)} \prod_{i=1}^{n+1} M_i (y_{i-1},y_i|x)
\tag{11.24}
$$
其中$Z_w(x)$为规范化因子，是n+1个矩阵的乘积的(start,stop)元素：
$$
Z_w(x) = \left( M_1(x) M_2(x) \cdots M_{n+1}(x) \right)_{\text{start,stop}}
\tag{11.25}
$$
注意，$y_0$=start与$y_{n+1}$=stop表示开始状态和终止状态，规范化因子$Z_w(x)$是以start为起点stop为终点，通过状态的所有路径$y_1 y_2 \cdots y_n$的非规范化概率$\prod_{i=1}^{n+1}M_i(y_{i-1},y_i|x)$之和

## 11.3 条件随机场的概率计算问题
条件随机场的概率计算问题是指：
给定条件随机场P(Y|X)，输入序列x和输出序列y，计算条件概率$P(Y_i=y_i|x)$，$P(Y_{i-1}=y_{i-1},Y_i=y_i|x)$以及相应的数学期望问题

### 11.3.1 前向-后向算法
对每个指标$i=0,1,\cdots,n+1$，定义前向向量$\alpha_i(x)$：
$$
\alpha_0(y|x) = 
\begin{cases}
1, &y=\text{start} \\
0, &否则
\end{cases}
\tag{11.26}
$$
递推公式为：
$$
\alpha_i^T(y_i |x) = \alpha_{i-1}^T(y_{i-1}|x) \left[ M_i(y_{i-1}y_i|x) \right],\, i=1,2,\cdots,n+1
\tag{11.27}
$$
又可表示为
$$
\alpha_i^T(x) = \alpha_{i-1}^T(x) M_i(x)
\tag{11.28}
$$
$\alpha_i(y_i |x)$表示在位置i的、标记是$y_i$、并且到位置i的前部分标记序列的非规范化概率，$y_i$的可取值有m个，所以$\alpha_i(y_i |x)$是m维列向量
同样，对每个指标$i=0,1,\cdots,n+1$，定义后向向量$\beta_i(x)$：
$$\begin{align}
\beta_{n+1}(y_{n+1}|x) = 
\begin{cases}
1, & y_{n+1} = \text{stop}\\
0, & 否则
\end{cases}
\tag{11.29}
\\
\beta_i(y_i|x) = \left[ M_i (y_i,y_{i+1}|x) \right] \beta_{i-1}(y_{i+1}|x) \tag{11.30}
\end{align}
$$
又可表示为
$$
\beta_i(x) = M_{i+1}(x) \beta_{i+1}(x)
\tag{11.31}
$$
$\beta_i(y_i|x)$表示在位置i的、标记为$y_i$、并且从i+1到n的后部分标记序列的非规范化概率
由前向-后向向量定义：
$$
Z(x) = \alpha_n^T(x) \cdot \mathbb{1} = \mathbb{1}^T \cdot \beta_1(x)
$$
这里，$\mathbb{1}$是元素均为1的m维列向量

### 11.3.2 概率计算
由前向-后向向量定义，容易计算：标记序列在位置i是标记$y_i$的条件概率，和在位置i-1和i、是标记$y_{i-1}$和$y_i$的条件概率
$$\begin{align}
P\left( Y_{i}=y_{i} | x \right) = \frac{\alpha_{i}^{\mathrm{T}} \left( y_{i} | x\right) \beta_{i}\left(y_{i} | x\right)} {Z(x)}
\tag{11.32}
\\
P\left(Y_{i-1}=y_{i-1}, Y_{i}=y_{i} | x\right)=\frac{\alpha_{i-1}^{\mathrm{T}}\left(y_{i-1} | x\right) M_{i}\left(y_{i-1}, y_{i} | x\right) \beta_{i}\left(y_{i} | x\right)}{Z(x)}
\tag{11.33}
\\
Z(x)=\alpha_{n}^{\mathrm{T}}(x) \cdot \mathbb{1}
\end{align}$$

### 11.3.3 期望值的计算
利用前向-后向向量，可以计算特征函数关于联合分布$P(X,Y)$和条件分布P(Y|X)的数学期望

#### 特征函数$f_k$关于条件分布$P(Y|X)$的数学期望
$$\begin{align}
E_{P(Y|X)} \left[ f_k \right] 
&= \sum_y P(y|x) f_k(y,x) \\
&= \sum_{i=1}^{n+1} \sum_{y_{i-1}y_i} f(y_{i-1},y_i,x,i) \frac{\alpha_{i-1}^T(y_{i-1}|x) M_i(y_{i-1},y_i | x) \beta_i(y_i|x)}{Z(x)}\\
k=1,2,\cdots,K
\end{align}
\tag{11.34}$$
其中
$$
Z(x) = \alpha_n^T (x) \cdot \mathbb{1}
$$

假设经验分布为$\tilde{P}(X)$
#### 特征函数$f_k$关于联合分布$P(X,Y)$的数学期望
$$\begin{align}
E_{P(X,Y)} \left[ f_k \right]
&= \sum_{x,y} P(x,y) \sum_{i=1}^{n+1} f_k(y_{i-1},y_i,x,i)\\
&= \sum_{x} \tilde{P}(x) \sum_y P(y|x) \sum_{i=1}^{n+1} f_k (y_{i-1},y_i,x,i)\\
&= \sum_{x} \tilde{P}(x) \sum_{i=1}^{n+1} \sum_{y_{t-1}y_i} f_k(y_{i-1},y_i,x,i) \frac{\alpha_{i-1}^T(y_{i-1}|x) M_i(y_{i-1},y_i | x) \beta_i(y_i|x)}{Z(x)}\\
k=1,2,\cdots,K
\end{align}
\tag{11.35}
$$

式(11.34)(11.35)是特征函数数学期望的一半计算公式。对于转移特征$t_k$，可以将始终的$f_k$换成$t_k$；状态特征$s_l$同理
有(11.32)~(11.35)，对于给定的观测序列x和标记序列y，可以通过一次前向扫描计算$\alpha_i$及Z(x)，通过一次后向扫描计算$\beta_i$，从而计算所有的概率和特征的期望

## 11.4 条件随机场的学习算法

### 11.4.1 改进的迭代尺度法
已知训练数据集，由此可知经验概率分布$\tilde{P}(X,Y)$。可以通过极大化训练数据的对数似然函数来模型参数

训练数据的对数似然函数为：
$$\begin{align}
L(w) 
&= L_{\tilde{P}} (P_w) \\
&= \log \prod_{x,y} P_w(y|x)^{\tilde{P}(x,y)} \\
&= \sum_{x,y} \tilde{P}(x,y) \log P_w(y|x)
\end{align}$$
当$P_w$是由(11.15)和(11.16)给出的条件随机场模型时，对数似然函数为：
$$\begin{align}
L(w) 
&= \sum_{x,y} \tilde{P}(x,y) \log P_w(y|x) \\
&= \sum_{x,y} \left[ \tilde{P}(x,y) \sum_{k=1}^K w_k f_k(y,x) - \tilde{P} (x,y) \log Z_w(x) \right] \\
&= \sum_{j=1}^N \sum_{k=1}^K w_k f_k (y_j,x_j) - sum_{j=1}^K \log Z_w (x_j)
\end{align}$$

改进的迭代尺度法，通过迭代的方法不断优化对数似然函数改变量的下界，达到极大化对数似然函数的目的
假设模型的当前参数向量为$w=(w_1,w_2,\cdots,w_k)^T$，向量的增量为$\delta = (\delta_1,\delta_2,\cdots,\delta_K)^T$，更新参数向量为$w+\delta = (w_1+\delta_1, w_2+\delta_2, \cdots, w_K + \delta_K)^T$
在每步迭代过程中，改进的尺度法通过依次求解(11.36)和(11.37)，得到$\delta = (\delta_1,\delta_2,\cdots,\delta_K)^T$
推导可见6.3.1

- 关于转移特征$t_k$的更新方程为
$$\begin{align} 
E_{\tilde{P}} \left[ t_{k} \right] 
&=\sum_{x,y} \tilde{P}(x, y) \sum_{i=1}^{n+1} t_{k} \left( y_{i-1}, y_{i}, x, i \right) \\ 
&=\sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n+1} t_{k} \left( y_{i-1}, y_{i}, x, i\ right) \exp \left(\delta_{k} T(x, y) \right) 
k=1,2,\cdots,K_1
\end{align}
\tag{11.36}$$
- 关于状态特征$s_l$的更新方程为
$$\begin{align}
E_{\tilde{P}} \left[ s_{l} \right] 
&=\sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^{n+1} s_{l} \left(y_{i}, x, i\right) \\ 
&=\sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n} s_{l} \left(y_{i}, x, i\right) \exp \left(\delta_{K_{1}+l} T(x, y)\right) 
\end{align}
\tag{11.37}
$$
这里，$T(x,y)$是数据$(x,y)$中出现所有特征数的综合
$$
T(x,y) = \sum_k f_k(y,x) = \sum_{k=1}^K \sum_{i=1}^{n+1} f_k(y_{i-1},y_i,x,i)
\tag{11.38}
$$

#### 算法11.1（条件随机场模型学习的改进的迭代尺度法）
**输入：** 特征函数$t_1,t_2,\cdots,t_{K_1}，s_1,s_2,\cdots,s_{K_2}$；经验分布$\tilde{P}(x,y)$
**输出：** 参数估计值$\hat{w}$；模型$P_{\hat{w}}$

1. 对所有$k \in \{1,2,\cdots,K \}$，取初值$w_k=0$
2. 对每一$k \in \{1,2,\cdots,K \}$：
    - (a)当$k=1,2,\cdots,K_1$时，令$\delta_k$是方程
$$
\sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n+1} t_k \left( y_{i-1},y_i,x,i \right) \exp \left(\delta_k t(x,y) \right) = E_{\tilde{P}} \left[ t_{k} \right] 
$$
的解
当$k=K_1+l,\ l=1,2,\cdots,K_2$时，令$\delta_{K_1+l}$是方程
$$
\sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n} s_{l} \left(y_{i}, x, i\right) \exp \left(\delta_{K_{1}+l} T(x, y)\right) = E_{\tilde{P}} \left[ s_{l} \right] 
$$
的解，式中T(x,y)由(11.38)给出
    - (b) 更新$w_k$值：$w_k \leftarrow w_k + delta_k$
3. 如果不是所有$w_k$都收敛，重复步骤2


#### 算法S    
在式(11.36)和(11.37)中，$T(x,y)$表示数据(x,y)中的特征总数，对不同的数据(x,y)取值可能不同。为了处理这个问题，定义松弛特征：
$$
s(x,y) = S - \sum_{i=1}^{n+1} \sum_{k=1}^K \f_k (y_{i-1},y_i,x,i)
\tag{11.39}
$$
式中S是一个常数
选择足够大的常数使得对训练数据集的所有数据(x,y)，$s(x,y) \ge 0$成立，这时特征总数可取S

由(11.36)，对于转移特征$t_k$，$\delta_k$的更新方程是：
$$\begin{align}
\sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n+1} t_k \left( y_{i-1},y_i,x,i \right) \exp \left(\delta_k S \right) = E_{\tilde{P}} \left[ t_{k} \right]  \tag{11.40} \\
\delta_k = \frac{1}{S} \log \frac{E_{\tilde{P}} \left[ t_{k} \right]}{E_P \left[ t_{k} \right]} \tag{11.41}
\end{align}$$
其中
$$
E_P \left[ t_{k} \right] = \sum_x \tilde{P}(x) \sum_{i=1}^{n+1} \sum_{y_{i-1} y_i} t_k(y_{i-1},y_i,x,i) \frac{\alpha_{i-1}^T(y_{i-1}|x) M_i(y_{i-1},y_i|x) \beta_i(y_i)|x}{Z(x)}
\tag{11.42}
$$
同样，由(11.37)，对于状态特征$s_l$，$\delta_k$的更新方程是：
$$\begin{align}
\sum_{x, y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n} s_{l}\left( y_{i}, x, i \right) \exp \left( \delta_{K_{1}+l} S \right) = E_{\tilde{P}} \left[ s_{l} \right] \tag{11.43} \\
\delta_{K_1+l} = \frac{1}{S} \log \frac{E_{\tilde{P}} \left[ s_l \right]}{E_P \left[ s_l \right]} \tag{11.44}
\end{align}$$
其中
$$
E_P \left[ s_l \right] = \sum_x \tilde{P}(x) \sum_{i=1}^n \sum_{y_i} s_l(y_i,x,i) \frac{\alpha_i^T(y_i|x) \beta_i(y_i|x)}{Z(x)}
\tag{11.46}
$$
算法S中需要使常数S取足够大，这样使每步迭代的增量向量会变大，算法收敛会变慢。故有算法T

#### 算法T
算法T对每个观测序列x计算其特征总数最大值T(x)
$$
T(x) = \max_{y} T(x,y)
\tag{11.46}
$$
利用前向-后向递推公式，易得：$T(x) = t$
这时，关于转移特征参数的更新方程可以写成：
$$\begin{align}
E_{\tilde{P}} \left[ t_k \right]
&= \sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i) \exp \left(\delta_k T(x) \right) \\
&= \sum_{x} \tilde{P}(x) \sum_y P(y|x) \sum_{i=1}^{n+1}t_k(y_{i-1},y_i,x,i) \exp \left(\delta_k T(x) \right) \\
&= \sum_x \tilde{P}(x) a_{k,t} \exp(\delta_k \cdot t)  \\
&= \sum_{t=0}^{T_{\text{max}}} a_{k,t} \beta_k^t
\tag{11.47}
\end{align}$$
这里，$a_{k,t}$是$t_k$的期待值，$\delta_k = \log \beta_k$。$\beta_k$是多项式方程(11.47)唯一的实根，可以用牛顿法求得。从而得到相关的$\delta_k$
同样，关于状态特征的参数更新方程可以写成：
$$\begin{align}
E_{\tilde{P}} \left[ s_l \right]
&= \sum_{x,y} \tilde{P}(x) P(y|x) \sum_{i=1}^{n} s_l(y_i,x,i) \exp \left(\delta_{K_1+l} T(x) \right) \\
&= \sum_x \tilde{P}(x) \sum_y P(y|x)  \sum_{i=1}^{n} s_l(y_i,x,i) \exp \left(\delta_{K_1+l} T(x) \right) \\
&= \sum_x \tilde{P}(x) b_{l,t} \exp(\delta_k \cdot t)
&= \sum_{t=0}^{T_{\text{max}}} b_{l,t} \gamma_l^t
\tag{11.48}
\end{align}$$
这里$b_{l,t}$是特征$s_l$的期望值，$\delta_l = \log \gamma_l$，$\gamma_l$是多项式方程(11.48)的唯一实根，也可用牛顿法求得

### 11.4.2 拟牛顿法
对条件随机场模型：
$$
P_{w}(y|x) = \frac {\exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)} {\sum_{y} \exp \left(\sum_{i=1}^{n} w_{i} f_{i}(x, y)\right)}
\tag{11.49}
$$
学习的优化目标函数是：
$$
\min_{w \in \mathbb{R}^n} f(w) = \sum_x \tilde{P}(x) \log \sum_y \exp \left( \sum_{i=1}^n w_i f_i(x,y) \right) - \sum_{x,y} \tilde{P}(x,y) \sum_{i=1}^n w_i f_i(x,y)
\tag{11.50}
$$
其梯度函数是
$$
g(w) = sum_{x,y} \tilde{P}(x) P_w(y|x) f(x,y) - E_{\tilde{P}(f)}
\tag{11.51}
$$
拟牛顿法的BFGS算法如下

#### 算法11.2（条件随机场模型学习的BFGS算法）
**输入：** 特征函数$f_1,f_2,\cdots,f_n$；经验分布$\tilde{P}(X,Y)$
**输出：** 最优参数值$\hat{w}$；最优模型$P_{\hat{w}}(y|x)$

1. 选定初始点$w^{(0)}$，取$\mathbf{B}_0$为正定对称矩阵，置k=0
2. 计算$g_k = g(w^{(k)})$。若$g_k=0$，则停止，否则3
3. 由$B_k p_k = -g_k$求出$p_k$
4. 一维搜索：求$\lambda_k$使得
$$
f \left( w^{(k)} + \lambda_k p_k \right) = \min_{\lambda \ge 0} f \left( w^{(k)} + \lambda p_k \right)
$$
5. 置$w^{(k+1)} = w^{(k)}+\lambda_k p_k$
6. 计算$g_{k+1} = g(w^{(k+1)})$。若$g_{k+1}=0$则停止计算，否则按下式求出$B_{k+1}$：
$$
B_{k+1} = B_k + \frac{y_k y_k^T}{y_k^T \delta_k} - \frac{B_{k} \delta_{k} \delta_{k}^{\mathrm{T}} B_{k}}{\delta_{k}^{\mathrm{T}} B_{k} \delta_{k}}
$$
其中，
$$
y_k = g_{k+1}-g_k,\, \delta_k = w^{(k+1)} - w^{(k)}
$$
7. 置k=k+1，转3



## 11.5 条件随机场的预测算法
**维特比算法**
给定条件随机场P(Y|X)和输入序列（观测序列）x，求条件概率最大的输出序列（标记序列）$y^*$，即：对观测序列进行标注

由(11.19)可得：
$$\begin{align}
y^{*} 
&=\arg \max _{y} P_{w}(y | x) \\ 
&=\arg \max _{y} \frac{\exp (w \cdot F(y, x))}{Z_{w}(x)} \\ 
&=\arg \max _{y} \exp (w \cdot F(y, x)) \\ 
&=\arg \max _{y}(w \cdot F(y, x)) 
\end{align}$$
于是，条件随机场的预测问题，称为求非规范化概率最大的最优路径问题
$$
\max_y \left( w \cdot F(y,x) \right)
\tag{11.52}
$$
这里，路径表示标记序列。其中
$$
\begin{array}{l}
{w=\left(w_{1}, w_{2}, \cdots, w_{K}\right)^{\mathrm{T}}} \\ 
{F(y, x)=\left(f_{1}(y, x), f_{2}(y, x), \cdots, f_{K}(y, x)\right)^{\mathrm{T}}} \\ 
{f_{k}(y, x)=\sum_{i=1}^{n} f_{k}\left(y_{i-1}, y_{i}, x, i\right), \quad k=1,2, \cdots, K}
\end{array}
$$
注意，这里只需要计算非规范化概率，而不必计算概率，可以大大提高效率
为求解最优路径，将(11.52)写成如下形式：
$$
\max_y \sum_{i=1}^n w \cdot F_i(y_{i-1},y_i,x)
\tag{11.53}
$$
其中，
$$
F_i(y_{i-1},y_i,x) = (f_1(y_{i-1},y_i,x,i), f_2(y_{i-1},y_i,x,i), \cdots, f_K(y_{i-1},y_i,x,i))^{\mathrm{T}}
$$
是局部特征向量


下面叙述维特比算法：
首先求出位置1的各个标记$j=1,2,\cdots,m$的非规范化概率：
$$
\delta_1(j) = w \cdots F_1(y_0 =\text{start}, y_1=j,x),\,j=1,2,\cdots,m
\tag{11.54}
$$
一般地，由递推公式，求出到位置i的各个标记$l=1,2,\cdots,m$的非规范化概率的最大值，同时记录非规范化概率最大值的路径
$$
\delta_i(l) = \max_{1 \le j \le m} \left\{ \delta_{i-1}(j) + w \cdot F_i(y_{i-1} = j, y_i = l,x) \right\},\, l = 1,2,\cdots,m
\tag{11.55}
$$
$$
\Psi_i(l) = \arg \max_{1 \le j \le m} \left\{ \delta_{i-1}(j) + w \cdot F_i(y_{i-1} = j, y_i = l,x) \right\},\, l = 1,2,\cdots,m
\tag{11.56}
$$
直到i=n时终止，这时求得非规范化概率的最大值是：
$$
\max_y (w \cdot F(y,x)) = \max_{1 \le j \le m} \delta_n(j)
\tag{11.57}
$$
及最优路径的重点
$$
y_n^* = \arg \max_{1 \le j \le m} \delta_n(j)
\tag{11.58}
$$
由此最优路径终点返回：
$$
y_i^* = \Psi_{i+1}(y_{i+1}^*),\, i=n-1,n-2,\cdots,1
\tag{11.59}
$$
求得最优路径$y^* = (y_1^*, y_2^*, \cdots, y_n^*)^{\mathrm{T}}$

#### 算法11.3（条件随机场预测的维特比算法）
**输入：** 模型特征向量$F(y,x)$和权值向量$w$，观测序列$x=(x_1,x_2,\cdots,x_n)$；
**输出：** 最优路径$y^* = (y_1^*, y_2^*, \cdots, y_n^*)$

1. 初始化
$$
\delta_1(j) = w \cdots F_1(y_0 =\text{start}, y_1=j,x),\,j=1,2,\cdots,m
$$
2. 递推。对$i=2,3,\cdots,n$
$$\begin{align}
\delta_i(l) = \max_{1 \le j \le m} \left\{ \delta_{i-1}(j) + w \cdot F_i(y_{i-1} = j, y_i = l,x ) \right\},\, l = 1,2,\cdots,m \\
\Psi_i(l) = \arg \max_{1 \le j \le m} \left\{ \delta_{i-1}(j) + w \cdot F_i(y_{i-1} = j, y_i = l,x) \right\},\, l = 1,2,\cdots,m
\end{align}$$
3. 终止
$$\begin{align}
\max_y (w \cdot F(y,x)) = \max_{1 \le j \le m} \delta_n(j) \\
y_n^* = \arg \max_{1 \le j \le m} \delta_n(j)
\end{align}$$
4. 返回路径
$$
y_i^* = \Psi_{i+1}(y_{i+1}^*),\, i=n-1,n-2,\cdots,1
$$

至此，求得最优路径$y^* = (y_1^*, y_2^*, \cdots, y_n^*)$

